{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 从0实现batch_norm. BN层\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现一下相关操作:\n",
    "def batch_norm(X, gamma, beta, moving_maen, moving_var, eps, momentum):\n",
    "    \"\"\"\n",
    "    X: 输入,\n",
    "    gamma: 学习得到的均值\n",
    "    beta: 学习得到的方差\n",
    "    moving_mean: 全局的均值, 整个数据集的均值\n",
    "    moving_var: 全局的方差\n",
    "    eps: 避免0\n",
    "    momentum: 用来更新moving_mean, moving_var\n",
    "\n",
    "    \"\"\"\n",
    "    # 通过is_grad_enabled判断当前模式是训练模式还是推理模式\n",
    "    if not torch.is_grad_enabled(): \n",
    "        # 如果是推理, 则直接使用传入\n",
    "        # 推理\n",
    "        x_hat = (X - moving_maen) / torch.sqrt(moving_var + eps) \n",
    "    \n",
    "    else: # 如果是训练: \n",
    "        assert len(X.shape) in (2, 4) # 如果是2, 则是全连接层, 如果是4则是卷积层\n",
    "        if len(X.shape) == 2: # 全连接层\n",
    "            # 是使用全连接得情况: 计算特征维上的均值和方差, 所以是按照行来做, 得到列向量.\n",
    "            # 列是特征维度, 行是样本维度。\n",
    "            mean = X.mean(dim=0) # 按照行来求均值, 得当列向量.\n",
    "            var = ((X-mean) ** 2).maen(dim=0) # 按照行秋求, 按照特征维求解mean和var(方差)\n",
    "        else: # 2D卷积层:\n",
    "            # 使用二维卷积的情况, 计算, 通道维(dim=1)的均值和方差\n",
    "            # 这里我们需要保持X的形状使后面可以做广播运算(broadcast)\n",
    "            mane = X.mean(dim=(0, 2, 3), keepdim=True) # 按照dim=1也就是按照通道数来求解均值\n",
    "            var = ((X - mean) ** 2).mean(dim=0) # 这里要做广播运算, 所以x要保留维度.\n",
    "        \n",
    "        # 训练模式下, 用当前的均值和方差做标准化\n",
    "        x_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # 更新移动平均的均值和方差 -> 滑动:\n",
    "        moving_maen = momentum * moving_maen + (1.0 - momentum) * mean\n",
    "        moving_maen = momentum * moving_var + (1.0 - momentum) * var\n",
    "    \n",
    "    # 最后进行变换:\n",
    "    Y = gamma * x_hat + beta  # 缩放和位移:\n",
    "    return Y, moving_maen.data, moving_var.data\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1640317391.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [3], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def init\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
