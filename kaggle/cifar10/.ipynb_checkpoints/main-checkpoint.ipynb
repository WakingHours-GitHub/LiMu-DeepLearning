{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wakinghours/programming/LiMu_DeepLearning/kaggle/cifar10'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import *\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "runtime_path = sys.path[0]\n",
    "runtime_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_GPUS() -> List[torch.device]:\n",
    "    devices = [torch.device(f\"cuda:{i}\") for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else torch.device(\"cpu\")\n",
    "\n",
    "devices = try_all_GPUS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wakinghours/programming/LiMu_DeepLearning/kaggle/cifar10/train/42325.png\n",
      " 42325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@7.527] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/home/wakinghours/programming/LiMu_DeepLearning/kaggle/cifar10/train/42325.png\n",
      "'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 83\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     80\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_path))\n\u001b[0;32m---> 83\u001b[0m CIFAR10_dataset()[\u001b[39m0\u001b[39;49m]\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36mCIFAR10_dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     44\u001b[0m file_name \u001b[39m=\u001b[39m file_path\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     45\u001b[0m \u001b[39mprint\u001b[39m(file_path, file_name)\n\u001b[0;32m---> 46\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(cv\u001b[39m.\u001b[39;49mimread(file_path))\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_dataset:\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m X, file_name\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/functional.py:137\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (F_pil\u001b[39m.\u001b[39m_is_pil_image(pic) \u001b[39mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy(pic) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be 2/3 dimensional. Got \u001b[39m\u001b[39m{\u001b[39;00mpic\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "path_join = lambda *args: os.path.join(*args)\n",
    "\n",
    "\n",
    "class CIFAR10_dataset(Dataset):\n",
    "    def __init__(self, type_dataset: str = \"train\", vaild_rate=0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.type_dataset = type_dataset\n",
    "        self.vaild_rate = vaild_rate\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(42),\n",
    "            transforms.RandomResizedCrop(32, (0.6, 1.0), ratio=(1.0, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Normalize([0.4914, 0.4822, 0.4465],  # normalize. 归一化.\n",
    "                                 [0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "        self.labels_dict = self.parse_csv2label()\n",
    "\n",
    "        self.root_path = path_join(runtime_path, \"train\")\n",
    "        if \"train\" == self.type_dataset:\n",
    "            # generate train and vaild dataset file.\n",
    "            self.shuffle_train_vaild()\n",
    "            # only generate in \"train\" mode.\n",
    "\n",
    "            with open(\"./train.txt\", \"r\") as f:\n",
    "                self.file_path_list = f.readlines()\n",
    "\n",
    "\n",
    "        elif \"vaild\" == self.type_dataset:\n",
    "            with open(\"./train_vaild.txt\", \"r\") as f:\n",
    "                self.file_path_list = f.readlines()\n",
    "\n",
    "        elif \"test\" == self.type_dataset:\n",
    "            self.root_path = path_join(runtime_path, \"test\")\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.4914, 0.4822, 0.4465],  # normalize. 归一化.\n",
    "                                    [0.2023, 0.1994, 0.2010])\n",
    "            ])\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.file_path_list[index]\n",
    "        file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        print(file_path, file_name)\n",
    "        X = self.transform(cv.imread(file_path))\n",
    "\n",
    "        if \"test\" == self.type_dataset:\n",
    "            return X, file_name\n",
    "        return X, self.labels_dict[file_name]\n",
    "\n",
    "    def parse_csv2label(self):\n",
    "        with open(\"./trainLabels.csv\", \"r\") as f:\n",
    "            return {ele[0]: ele[1] for ele in [line.strip().split(',') for line in f.readlines()][1:]}\n",
    "\n",
    "    def shuffle_train_vaild(self):\n",
    "        len = self.__len__()\n",
    "        # print(len)\n",
    "\n",
    "        try:\n",
    "            file_name_list = os.listdir(self.root_path)\n",
    "            random.shuffle(file_name_list)\n",
    "\n",
    "            with open(path_join(self.root_path, \"../\", \"train.txt\"), \"w\") as train_file_writer:\n",
    "                train_file_writer.write(\n",
    "                    \"\\n\".join([path_join(self.root_path,  file_name)\n",
    "                              for file_name in file_name_list[0: int(len*(1-self.vaild_rate))]])\n",
    "                )\n",
    "\n",
    "            with open(path_join(self.root_path, \"../\",  \"train_vaild.txt\"), \"w\") as train_file_writer:\n",
    "                train_file_writer.write(\n",
    "                    \"\\n\".join([path_join(self.root_path,  file_name)\n",
    "                              for file_name in file_name_list[int(len*(1-self.vaild_rate)):]])\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"error: \", e)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root_path))\n",
    "\n",
    "\n",
    "CIFAR10_dataset()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
