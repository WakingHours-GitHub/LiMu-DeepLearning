{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4916e809",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 多GPU的简洁实现\n",
    ":label:`sec_multi_gpu_concise`\n",
    "\n",
    "每个新模型的并行计算都从零开始实现是无趣的。此外，优化同步工具以获得高性能也是有好处的。下面我们将展示如何使用深度学习框架的高级API来实现这一点。数学和算法与 :numref:`sec_multi_gpu`中的相同。不出所料，你至少需要两个GPU来运行本节的代码。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77470e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:58:41.291688Z",
     "iopub.status.busy": "2022-07-31T02:58:41.291307Z",
     "iopub.status.idle": "2022-07-31T02:58:44.886356Z",
     "shell.execute_reply": "2022-07-31T02:58:44.885341Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 多GPU的简介实现. \n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0b2df",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "## [**简单网络**]\n",
    "\n",
    "让我们使用一个比 :numref:`sec_multi_gpu`的LeNet更有意义的网络，它依然能够容易地和快速地训练。我们选择的是 :cite:`He.Zhang.Ren.ea.2016`中的ResNet-18。因为输入的图像很小，所以稍微修改了一下。与 :numref:`sec_resnet`的区别在于，我们在开始时使用了更小的卷积核、步长和填充，而且删除了最大汇聚层。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7000e5f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:58:44.890914Z",
     "iopub.status.busy": "2022-07-31T02:58:44.890281Z",
     "iopub.status.idle": "2022-07-31T02:58:44.902720Z",
     "shell.execute_reply": "2022-07-31T02:58:44.901821Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# resnet18\n",
    "#@save\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    \"\"\"稍加修改的ResNet-18模型\"\"\"\n",
    "    def resnet_block(in_channels, out_channels, num_residuals,\n",
    "                     first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(d2l.Residual(in_channels, out_channels,\n",
    "                                        use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(d2l.Residual(out_channels, out_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "\n",
    "    # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU())\n",
    "    net.add_module(\"resnet_block1\", resnet_block(\n",
    "        64, 64, 2, first_block=True))\n",
    "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
    "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1,1)))\n",
    "    net.add_module(\"fc\", nn.Sequential(nn.Flatten(),\n",
    "                                       nn.Linear(512, num_classes)))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf9b25",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## 网络初始化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9fedf",
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "我们将在训练回路中初始化网络。请参见 :numref:`sec_numerical_stability`复习初始化方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497ddb5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:58:44.907197Z",
     "iopub.status.busy": "2022-07-31T02:58:44.906529Z",
     "iopub.status.idle": "2022-07-31T02:58:45.034277Z",
     "shell.execute_reply": "2022-07-31T02:58:45.033589Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "net = resnet18(10)\n",
    "# 获取GPU列表\n",
    "devices = d2l.try_all_gpus()\n",
    "# 我们将在训练代码实现中初始化网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19654ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d807e8",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## [**训练**]\n",
    "\n",
    "如前所述，用于训练的代码需要执行几个基本功能才能实现高效并行：\n",
    "\n",
    "* 需要在所有设备上初始化网络参数。\n",
    "* 在数据集上迭代时，要将小批量数据分配到所有设备上。\n",
    "* 跨设备并行计算损失及其梯度。\n",
    "* 聚合梯度，并相应地更新参数。\n",
    "\n",
    "最后，并行地计算精确度和发布网络的最终性能。除了需要拆分和聚合数据外，训练代码与前几章的实现非常相似。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d2b448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:58:45.038650Z",
     "iopub.status.busy": "2022-07-31T02:58:45.038082Z",
     "iopub.status.idle": "2022-07-31T02:58:45.046794Z",
     "shell.execute_reply": "2022-07-31T02:58:45.045885Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def train(net, num_gpus, batch_size, lr):\n",
    "    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "    devices = [d2l.try_gpu(i) for i in range(num_gpus)]\n",
    "    print(devices)\n",
    "\n",
    "    def init_weights(m):\n",
    "        if type(m) in [nn.Linear, nn.Conv2d]:\n",
    "            nn.init.normal_(m.weight, std=0.01)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    # 下面是主要的差别: \n",
    "    # 在多个GPU上设置模型\n",
    "    net = nn.DataParallel(net, device_ids=devices) # 数据并行. 给定net, 然后给定device的list. 返回一个新的net\n",
    "    # 那么pytorch就知道在那些个device复制我们的grad. 通过这一行代码pytorch就知道将net切分开. \n",
    "    # 那么它等价于帮助我们重写了net.forward()函数, 已经将我们手动实现的东西写再里面了.\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    timer, num_epochs = d2l.Timer(), 10\n",
    "    animator = d2l.Animator('epoch', 'test acc', xlim=[1, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        timer.start()\n",
    "        for X, y in train_iter: # 这个地方, 跟之前单机没什么区别, \n",
    "            # 因为pytoch知道DataParallel()我们是再做单机多卡的GPU训练. 框架已经帮助我们做好了很多事\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(devices[0]), y.to(devices[0])\n",
    "            l = loss(net(X), y) # pytorch已经做好. \n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        timer.stop()\n",
    "        animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(net, test_iter),))\n",
    "    print(f'测试精度：{animator.Y[0][-1]:.2f}，{timer.avg():.1f}秒/轮，'\n",
    "          f'在{str(devices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991f825",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "让我们看看这在实践中是如何运作的。我们先[**在单个GPU上训练网络**]进行预热。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26020181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T02:58:45.049814Z",
     "iopub.status.busy": "2022-07-31T02:58:45.049271Z",
     "iopub.status.idle": "2022-07-31T03:01:17.778247Z",
     "shell.execute_reply": "2022-07-31T03:01:17.777522Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://192.168.254.220/ to ../data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File not found or corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(net, num_gpus\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39m# gpu: 1的情况. \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, num_gpus, batch_size, lr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(net, num_gpus, batch_size, lr):\n\u001b[0;32m----> 2\u001b[0m     train_iter, test_iter \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39;49mload_data_fashion_mnist(batch_size)\n\u001b[1;32m      3\u001b[0m     devices \u001b[39m=\u001b[39m [d2l\u001b[39m.\u001b[39mtry_gpu(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_gpus)]\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(devices)\n",
      "File \u001b[0;32m~/miniconda3/envs/limu/lib/python3.9/site-packages/d2l/torch.py:216\u001b[0m, in \u001b[0;36mload_data_fashion_mnist\u001b[0;34m(batch_size, resize)\u001b[0m\n\u001b[1;32m    214\u001b[0m     trans\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, transforms\u001b[39m.\u001b[39mResize(resize))\n\u001b[1;32m    215\u001b[0m trans \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(trans)\n\u001b[0;32m--> 216\u001b[0m mnist_train \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mFashionMNIST(\n\u001b[1;32m    217\u001b[0m     root\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../data\u001b[39;49m\u001b[39m\"\u001b[39;49m, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, transform\u001b[39m=\u001b[39;49mtrans, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    218\u001b[0m mnist_test \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mFashionMNIST(\n\u001b[1;32m    219\u001b[0m     root\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../data\u001b[39m\u001b[39m\"\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, transform\u001b[39m=\u001b[39mtrans, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m (data\u001b[39m.\u001b[39mDataLoader(mnist_train, batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m                         num_workers\u001b[39m=\u001b[39mget_dataloader_workers()),\n\u001b[1;32m    222\u001b[0m         data\u001b[39m.\u001b[39mDataLoader(mnist_test, batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    223\u001b[0m                         num_workers\u001b[39m=\u001b[39mget_dataloader_workers()))\n",
      "File \u001b[0;32m~/miniconda3/envs/limu/lib/python3.9/site-packages/torchvision/datasets/mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[1;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/limu/lib/python3.9/site-packages/torchvision/datasets/mnist.py:187\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 187\u001b[0m     download_and_extract_archive(url, download_root\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_folder, filename\u001b[39m=\u001b[39;49mfilename, md5\u001b[39m=\u001b[39;49mmd5)\n\u001b[1;32m    188\u001b[0m \u001b[39mexcept\u001b[39;00m URLError \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m    189\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to download (trying next):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/limu/lib/python3.9/site-packages/torchvision/datasets/utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:\n\u001b[1;32m    432\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(url)\n\u001b[0;32m--> 434\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[1;32m    436\u001b[0m archive \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    437\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting \u001b[39m\u001b[39m{\u001b[39;00marchive\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mextract_root\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/limu/lib/python3.9/site-packages/torchvision/datasets/utils.py:155\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m# check integrity of downloaded file\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFile not found or corrupted.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: File not found or corrupted."
     ]
    }
   ],
   "source": [
    "train(net, num_gpus=1, batch_size=256, lr=0.1)\n",
    "# gpu: 1的情况. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56e6b2",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "接下来我们[**使用2个GPU进行训练**]。与 :numref:`sec_multi_gpu`中评估的LeNet相比，ResNet-18的模型要复杂得多。这就是显示并行化优势的地方，计算所需时间明显大于同步参数需要的时间。因为并行化开销的相关性较小，因此这种操作提高了模型的可伸缩性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275b0f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T03:01:17.781600Z",
     "iopub.status.busy": "2022-07-31T03:01:17.781375Z",
     "iopub.status.idle": "2022-07-31T03:02:52.189712Z",
     "shell.execute_reply": "2022-07-31T03:02:52.188985Z"
    },
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a non cpu device, but got: cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(net, num_gpus\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mbatch_size影响的是什么. 就是我们每次抽取dataloader时候的数据多样性, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m如果你的batch_size太大了, 那么每次抽取的data可能很多都是相同的, 那么你的数据多样性就较小, 在做梯度的时候实际上是平均了\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m差不多的样本是在做浪费, 因为梯度是做均值的.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m所以训练效果不好. 所以这时我们应该调小一点batch_size\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [9], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, num_gpus, batch_size, lr)\u001b[0m\n\u001b[1;32m      8\u001b[0m net\u001b[39m.\u001b[39mapply(init_weights)\n\u001b[1;32m     10\u001b[0m \u001b[39m# 下面是主要的差别: \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# 在多个GPU上设置模型\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m net \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mDataParallel(net, device_ids\u001b[39m=\u001b[39;49mdevices) \u001b[39m# 数据并行. 给定net, 然后给定device的list. 返回一个新的net\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# 那么pytorch就知道在那些个device复制我们的grad. 通过这一行代码pytorch就知道将net切分开. \u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# 那么它等价于帮助我们重写了net.forward()函数, 已经将我们手动实现的东西写再里面了.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m trainer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(net\u001b[39m.\u001b[39mparameters(), lr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:138\u001b[0m, in \u001b[0;36mDataParallel.__init__\u001b[0;34m(self, module, device_ids, output_device, dim)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim \u001b[39m=\u001b[39m dim\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule \u001b[39m=\u001b[39m module\n\u001b[0;32m--> 138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids \u001b[39m=\u001b[39m [_get_device_index(x, \u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_ids]\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device \u001b[39m=\u001b[39m _get_device_index(output_device, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(device_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim \u001b[39m=\u001b[39m dim\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule \u001b[39m=\u001b[39m module\n\u001b[0;32m--> 138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids \u001b[39m=\u001b[39m [_get_device_index(x, \u001b[39mTrue\u001b[39;49;00m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_ids]\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device \u001b[39m=\u001b[39m _get_device_index(output_device, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(device_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:524\u001b[0m, in \u001b[0;36m_get_device_index\u001b[0;34m(device, optional, allow_cpu)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, torch\u001b[39m.\u001b[39mdevice):\n\u001b[1;32m    523\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_cpu \u001b[39mand\u001b[39;00m device\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 524\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mExpected a non cpu device, but got: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(device))\n\u001b[1;32m    525\u001b[0m     device_idx \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m device\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m device\u001b[39m.\u001b[39mindex\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a non cpu device, but got: cpu"
     ]
    }
   ],
   "source": [
    "train(net, num_gpus=2, batch_size=512, lr=0.2)\n",
    "\"\"\"\n",
    "batch_size影响的是什么. 就是我们每次抽取dataloader时候的数据多样性, \n",
    "如果你的batch_size太大了, 那么每次抽取的data可能很多都是相同的, 那么你的数据多样性就较小, 在做梯度的时候实际上是平均了\n",
    "差不多的样本是在做浪费, 因为梯度是做均值的.\n",
    "所以训练效果不好. 所以这时我们应该调小一点batch_size\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379e501",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pid = os.getpid()\n",
    "\n",
    "!kill -9 $pid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d5538",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "## 小结\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61725fad",
   "metadata": {
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "* 神经网络可以在（可找到数据的）单GPU上进行自动评估。\n",
    "* 每台设备上的网络需要先初始化，然后再尝试访问该设备上的参数，否则会遇到错误。\n",
    "* 优化算法在多个GPU上自动聚合。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95e353",
   "metadata": {
    "origin_pos": 29
   },
   "source": [
    "## 练习\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64afddc4",
   "metadata": {
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "1. 本节使用ResNet-18，请尝试不同的迭代周期数、批量大小和学习率，以及使用更多的GPU进行计算。如果使用$16$个GPU（例如，在AWS p2.16xlarge实例上）尝试此操作，会发生什么？\n",
    "1. 有时候不同的设备提供了不同的计算能力，我们可以同时使用GPU和CPU，那应该如何分配工作？为什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff7d79c",
   "metadata": {
    "origin_pos": 33,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2803)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
