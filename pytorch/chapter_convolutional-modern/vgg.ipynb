{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9233a8c1",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 使用块的网络（VGG）\n",
    ":label:`sec_vgg`\n",
    "\n",
    "虽然AlexNet证明深层神经网络卓有成效，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络。\n",
    "在下面的几个章节中，我们将介绍一些常用于设计深层神经网络的启发式概念。\n",
    "\n",
    "与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构的设计也逐渐变得更加抽象。研究人员开始从单个神经元的角度思考问题，发展到整个层，现在又转向块，重复层的模式。\n",
    "\n",
    "使用块的想法首先出现在牛津大学的[视觉几何组（visualgeometry group）](http://www.robots.ox.ac.uk/~vgg/)的*VGG网络*中。通过使用循环和子程序，可以很容易地在任何现代深度学习框架的代码中实现这些重复的架构。\n",
    "\n",
    "## (**VGG块**)\n",
    "\n",
    "经典卷积神经网络的基本组成部分是下面的这个序列：\n",
    "\n",
    "1. 带填充以保持分辨率的卷积层；\n",
    "1. 非线性激活函数，如ReLU；\n",
    "1. 汇聚层，如最大汇聚层。\n",
    "\n",
    "而一个VGG块与之类似，由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层。在最初的VGG论文中 :cite:`Simonyan.Zisserman.2014`，作者使用了带有$3\\times3$卷积核、填充为1（保持高度和宽度）的卷积层，和带有$2 \\times 2$汇聚窗口、步幅为2（每个块后的分辨率减半）的最大汇聚层。在下面的代码中，我们定义了一个名为`vgg_block`的函数来实现一个VGG块。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1996bd1",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "该函数有三个参数，分别对应于卷积层的数量`num_convs`、输入通道的数量`in_channels`\n",
    "和输出通道的数量`out_channels`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b34d2999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T03:52:47.721072Z",
     "iopub.status.busy": "2022-07-31T03:52:47.720698Z",
     "iopub.status.idle": "2022-07-31T03:52:51.465067Z",
     "shell.execute_reply": "2022-07-31T03:52:51.464270Z"
    },
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# 首先我们实现的是VGG块, 也就是多少个卷积层. \n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels, out_channels,kernel_size=3, padding=1)\n",
    "            ) \n",
    "        layers.append(nn.ReLU()) # 然后再每一层增加一个ReLU.\n",
    "        in_channels = out_channels # 然后每个输入和输出都是一样的(除了第一个.)\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2)) # 最后增加一个最大池化\n",
    "    return nn.Sequential(*layers) # 最后丢到Sequential的块中作为一个Module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84792063",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## [**VGG网络**]\n",
    "\n",
    "与AlexNet、LeNet一样，VGG网络可以分为两部分：第一部分主要由卷积层和汇聚层组成，第二部分由全连接层组成。如 :numref:`fig_vgg`中所示。\n",
    "\n",
    "![从AlexNet到VGG，它们本质上都是块设计。](../img/vgg.svg)\n",
    ":width:`400px`\n",
    ":label:`fig_vgg`\n",
    "\n",
    "VGG神经网络连接 :numref:`fig_vgg`的几个VGG块（在`vgg_block`函数中定义）。其中有超参数变量`conv_arch`。该变量指定了每个VGG块里卷积层个数和输出通道数。全连接模块则与AlexNet中的相同。\n",
    "\n",
    "原始VGG网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。\n",
    "第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到512。由于该网络使用8个卷积层和3个全连接层，因此它通常被称为VGG-11。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7d54c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T03:52:51.469033Z",
     "iopub.status.busy": "2022-07-31T03:52:51.468465Z",
     "iopub.status.idle": "2022-07-31T03:52:51.472485Z",
     "shell.execute_reply": "2022-07-31T03:52:51.471807Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# 告诉你的一个架构. \n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "# 非常经典的结构, 因为我们是使用的maxpooling, K=2*2, stride=2, 所以我们的高宽是减半的. 然后我们让我们的通道数增加. \n",
    "# 这也是一个非常常用的架构这就告诉你有5个VGG块,\n",
    "# 第一块是1个卷积层, 64个输出通道, \n",
    "# 第三块是2个卷积层高, 256个输出通道 -> out_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efaa62",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "下面的代码实现了VGG-11。可以通过在`conv_arch`上执行for循环来简单实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a3fe21d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T03:52:51.475652Z",
     "iopub.status.busy": "2022-07-31T03:52:51.475145Z",
     "iopub.status.idle": "2022-07-31T03:52:52.675313Z",
     "shell.execute_reply": "2022-07-31T03:52:52.674597Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    # 卷积层部分\n",
    "    for (num_convs, out_channels) in conv_arch: # 根据你的每一块进行调用.\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels # 这一次的输出等等于下一次的输入层,. \n",
    "\n",
    "    return nn.Sequential(\n",
    "        *conv_blks,\n",
    "        # 准备全连接层\n",
    "        nn.Flatten(),\n",
    "        # 全连接层部分 -> 和AlexNet一样的全连接层.\n",
    "        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10))\n",
    "\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a8436",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "接下来，我们将构建一个高度和宽度为224的单通道数据样本，以[**观察每个层输出的形状**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56f99ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T03:52:52.678880Z",
     "iopub.status.busy": "2022-07-31T03:52:52.678378Z",
     "iopub.status.idle": "2022-07-31T03:52:52.742694Z",
     "shell.execute_reply": "2022-07-31T03:52:52.741990Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 224, 224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',X.shape)\n",
    "\n",
    "# 因为我们是一块一块放进去的, 所以我们不必要关注每层的形状, 而是关注一块一块, 每一块的输出情况.\n",
    "# 我们发现每一个VGG块都是, 我们的宽高减半, 然后通道数翻倍. 这是一个非常经典的设计. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e7fe4",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "正如你所看到的，我们在每个块的高度和宽度减半，最终高度和宽度都为7。最后再展平表示，送入全连接层处理。\n",
    "\n",
    "## 训练模型\n",
    "\n",
    "[**由于VGG-11比AlexNet计算量更大，因此我们构建了一个通道数较少的网络**]，足够用于训练Fashion-MNIST数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b7046b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T03:52:52.748247Z",
     "iopub.status.busy": "2022-07-31T03:52:52.747750Z",
     "iopub.status.idle": "2022-07-31T03:52:53.148450Z",
     "shell.execute_reply": "2022-07-31T03:52:53.147715Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (5): Flatten(start_dim=1, end_dim=-1)\n",
      "  (6): Linear(in_features=6272, out_features=4096, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.5, inplace=False)\n",
      "  (9): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (10): ReLU()\n",
      "  (11): Dropout(p=0.5, inplace=False)\n",
      "  (12): Linear(in_features=4096, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# VGG11: 8个卷积层 + 3个全连接层. \n",
    "# 因为VGG11太大了, 所以这里我们构建了一个通道数比较小的网络来进行训练, 就是上面通道数的基础上,除以4, 这样足以训练我们的Fashion-MNIST网络.\n",
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch)\n",
    "print(net) # 打印一下创建的VGG网络. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712d3e1",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "除了使用略高的学习率外，[**模型训练**]过程与 :numref:`sec_alexnet`中的AlexNet类似。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a88053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T03:52:53.153411Z",
     "iopub.status.busy": "2022-07-31T03:52:53.152929Z",
     "iopub.status.idle": "2022-07-31T03:58:00.510821Z",
     "shell.execute_reply": "2022-07-31T03:58:00.509898Z"
    },
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 7.80 GiB total capacity; 1.74 GiB already allocated; 27.69 MiB free; 1.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lr, num_epochs, batch_size \u001b[39m=\u001b[39m \u001b[39m0.05\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m128\u001b[39m\n\u001b[1;32m      2\u001b[0m train_iter, test_iter \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mload_data_fashion_mnist(batch_size, resize\u001b[39m=\u001b[39m\u001b[39m224\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m d2l\u001b[39m.\u001b[39mtrain_ch6(net, train_iter, test_iter, num_epochs, lr, d2l\u001b[39m.\u001b[39mtry_gpu())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/d2l/torch.py:485\u001b[0m, in \u001b[0;36mtrain_ch6\u001b[0;34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m    483\u001b[0m net\u001b[39m.\u001b[39mapply(init_weights) \u001b[39m# apply, trverse moudl in net.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtraining on\u001b[39m\u001b[39m'\u001b[39m, device) \u001b[39m# \u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m net\u001b[39m.\u001b[39;49mto(device) \u001b[39m# to GPU. device=try_GPU()\u001b[39;00m\n\u001b[1;32m    486\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(net\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m    487\u001b[0m loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 7.80 GiB total capacity; 1.74 GiB already allocated; 27.69 MiB free; 1.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "lr, num_epochs, batch_size = 0.05, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())\n",
    "# 可以看见, 虽然VGG11已经是VGG系列中比较小的网络了, 并且我们还将通道数除以4了, 但是他每秒训练的样本数还是相对于AlexNet减半了\n",
    "# 每秒训练2562个样本. \n",
    "# 通道数减除以4, 可以认为复杂度减小了16倍, 因为是输入和输出. \n",
    "# 不过精度还是非常不错的. \n",
    "# 不过这里我的显存不够了, 所以直接报红了.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc15869",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "## 小结\n",
    "\n",
    "* VGG-11使用可复用的卷积块构造网络。不同的VGG模型可通过每个块中卷积层数量和输出通道数量的差异来定义。\n",
    "* 块的使用导致网络定义的非常简洁。使用块可以有效地设计复杂的网络。\n",
    "* 在VGG论文中，Simonyan和Ziserman尝试了各种架构。特别是他们发现深层且窄的卷积（即$3 \\times 3$）比较浅层且宽的卷积更有效。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 打印层的尺寸时，我们只看到8个结果，而不是11个结果。剩余的3层信息去哪了？\n",
    "1. 与AlexNet相比，VGG的计算要慢得多，而且它还需要更多的显存。分析出现这种情况的原因。\n",
    "1. 尝试将Fashion-MNIST数据集图像的高度和宽度从224改为96。这对实验有什么影响？\n",
    "1. 请参考VGG论文 :cite:`Simonyan.Zisserman.2014`中的表1构建其他常见模型，如VGG-16或VGG-19。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff1c05",
   "metadata": {
    "origin_pos": 23,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1866)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
