{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 默认是在notebook里面显示图形.\n",
    "# 我们将从0开始实现整个方法, 包括数据流水线, 模型, 损失函数, 和小批量随机梯度下降优化器‘\n",
    "# 现在使用的都是小批量随机梯度下降, 梯度是很贵的. 因此\n",
    "# 可以帮助从底层了解我们的模型.\n",
    "\n",
    "import torch  # torch\n",
    "from d2l import torch as d2l  # 放在d2l包.\n",
    "import random\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_examples = 100\n",
    "\n",
    "# 生成数据集. 好处是我们知道参数, 这样可以比较优化结果和实际参数的区别. 并且数据量较小, 方便我们理解整个深度学习的过程\n",
    "def synthetic_data(w, b, num_examples):  # @save\n",
    "    \"\"\"生成Y = wX + b的噪声\"\"\"\n",
    "    x = torch.normal(0, 1, (num_examples, len(w)))  # 参数分别是: 均值, 标准差, 以及形状. 也就是多少个样本.\n",
    "    # 矩阵乘积要满足条件, 因此必须使用len(w), 在和w相乘前.\n",
    "    y = torch.matmul(x, w) + b  # 计算b, 默认使用其中元素进行运算\n",
    "    # 加上随机噪声\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return x, y.reshape((-1, 1))  # 成为列向量.\n",
    "\n",
    "# 真实True\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "\n",
    "# 生成随机数据\n",
    "features, labels = synthetic_data(true_w, true_b, num_examples)  # 生成1000个样本数据."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features tensor([[-2.0615,  0.0359],\n",
      "        [ 1.0301, -1.3225],\n",
      "        [-1.4317,  1.0843],\n",
      "        [-2.6109,  0.8439],\n",
      "        [-0.3010,  0.2469],\n",
      "        [ 0.2209, -0.0353],\n",
      "        [-0.6492, -0.4403],\n",
      "        [ 1.1196,  0.8198],\n",
      "        [ 0.7070, -0.2932],\n",
      "        [-0.4004, -0.4504],\n",
      "        [-0.4605,  1.3740],\n",
      "        [ 2.3324, -0.8164],\n",
      "        [ 1.1595,  1.1712],\n",
      "        [ 0.0208, -2.2443],\n",
      "        [ 1.5806,  0.2634],\n",
      "        [ 2.6939,  2.5766],\n",
      "        [ 0.6000, -0.8738],\n",
      "        [-0.5394, -0.0786],\n",
      "        [-1.2050, -0.8925],\n",
      "        [-1.8701,  0.7875],\n",
      "        [ 0.4440,  1.1028],\n",
      "        [ 1.8384,  0.1168],\n",
      "        [ 0.2224,  0.0318],\n",
      "        [-1.2939, -0.4517],\n",
      "        [-0.6021, -0.0430],\n",
      "        [ 0.9436, -1.3536],\n",
      "        [ 0.3027,  1.4992],\n",
      "        [-0.6881, -0.3886],\n",
      "        [ 1.8186,  1.9086],\n",
      "        [ 0.8407, -0.3475],\n",
      "        [-0.0899, -0.1616],\n",
      "        [-1.1364,  0.6506],\n",
      "        [ 1.0518, -0.1950],\n",
      "        [-1.1204, -0.6459],\n",
      "        [-1.7514, -0.7393],\n",
      "        [ 0.8109,  1.0026],\n",
      "        [-0.3645,  0.5993],\n",
      "        [-0.3633, -1.3634],\n",
      "        [-0.7934, -1.4077],\n",
      "        [ 0.4143,  1.4314],\n",
      "        [ 0.1926,  0.8750],\n",
      "        [ 0.2471,  1.4064],\n",
      "        [ 0.6932,  0.5928],\n",
      "        [-0.6744, -0.2896],\n",
      "        [-0.9562, -0.7259],\n",
      "        [ 1.3595, -0.1495],\n",
      "        [-1.0180, -0.8317],\n",
      "        [-0.9225,  0.9428],\n",
      "        [-0.1862,  0.7060],\n",
      "        [-1.5696,  0.3773],\n",
      "        [ 2.8154, -0.5978],\n",
      "        [ 0.3100,  1.0689],\n",
      "        [-0.0682,  2.3416],\n",
      "        [ 1.2475,  0.5712],\n",
      "        [ 0.6635, -0.0902],\n",
      "        [-0.7217, -0.5649],\n",
      "        [-1.0283, -1.0142],\n",
      "        [-0.3334, -0.7783],\n",
      "        [-1.0289,  0.9787],\n",
      "        [-1.1498, -0.3073],\n",
      "        [ 0.7152, -0.8951],\n",
      "        [-0.5267,  1.1334],\n",
      "        [ 0.7342, -0.3204],\n",
      "        [ 1.1791, -1.2731],\n",
      "        [-1.5878,  0.0978],\n",
      "        [ 1.5053,  1.9595],\n",
      "        [ 0.1497,  1.1694],\n",
      "        [-0.1746,  0.9497],\n",
      "        [ 2.6336, -0.6005],\n",
      "        [ 0.5232, -0.1090],\n",
      "        [ 0.3504,  0.9798],\n",
      "        [-0.8957,  0.4331],\n",
      "        [ 0.2523,  0.3875],\n",
      "        [ 1.5277,  1.4972],\n",
      "        [-0.4897,  0.5605],\n",
      "        [ 0.8135,  1.8626],\n",
      "        [ 0.4358, -0.6713],\n",
      "        [ 0.9643, -0.4877],\n",
      "        [ 1.0870, -0.5117],\n",
      "        [-0.6698,  0.6964],\n",
      "        [-0.7641, -0.1971],\n",
      "        [ 1.4494,  0.5637],\n",
      "        [-0.0778,  0.9784],\n",
      "        [-0.2031, -0.9909],\n",
      "        [ 0.9980,  1.9982],\n",
      "        [-0.6318,  2.0035],\n",
      "        [ 0.7244,  1.1260],\n",
      "        [ 1.0192, -0.1965],\n",
      "        [ 0.4604, -0.7165],\n",
      "        [-0.4706,  1.2125],\n",
      "        [ 1.8686, -0.9821],\n",
      "        [-0.7950,  0.7337],\n",
      "        [-0.9212,  0.3458],\n",
      "        [ 0.2192,  1.9365],\n",
      "        [ 0.0121,  1.6209],\n",
      "        [ 0.3653,  0.5671],\n",
      "        [ 0.3965, -0.7193],\n",
      "        [-0.4557,  1.7554],\n",
      "        [ 1.4118, -0.5026],\n",
      "        [ 0.1451, -0.2975]]) labels tensor([[-0.0480],\n",
      "        [10.7496],\n",
      "        [-2.3443],\n",
      "        [-3.8923],\n",
      "        [ 2.7441],\n",
      "        [ 4.7686],\n",
      "        [ 4.4137],\n",
      "        [ 3.6505],\n",
      "        [ 6.5968],\n",
      "        [ 4.9323],\n",
      "        [-1.3873],\n",
      "        [11.6337],\n",
      "        [ 2.5400],\n",
      "        [11.8556],\n",
      "        [ 6.4705],\n",
      "        [ 0.8301],\n",
      "        [ 8.3675],\n",
      "        [ 3.3731],\n",
      "        [ 4.8137],\n",
      "        [-2.2080],\n",
      "        [ 1.3468],\n",
      "        [ 7.4600],\n",
      "        [ 4.5369],\n",
      "        [ 3.1357],\n",
      "        [ 3.1296],\n",
      "        [10.6956],\n",
      "        [-0.2958],\n",
      "        [ 4.1390],\n",
      "        [ 1.3383],\n",
      "        [ 7.0551],\n",
      "        [ 4.5667],\n",
      "        [-0.2778],\n",
      "        [ 6.9643],\n",
      "        [ 4.1634],\n",
      "        [ 3.2071],\n",
      "        [ 2.4124],\n",
      "        [ 1.4410],\n",
      "        [ 8.1053],\n",
      "        [ 7.4192],\n",
      "        [ 0.1687],\n",
      "        [ 1.6218],\n",
      "        [-0.0843],\n",
      "        [ 3.5643],\n",
      "        [ 3.8285],\n",
      "        [ 4.7525],\n",
      "        [ 7.4410],\n",
      "        [ 4.9871],\n",
      "        [-0.8561],\n",
      "        [ 1.4434],\n",
      "        [-0.2214],\n",
      "        [11.8668],\n",
      "        [ 1.1801],\n",
      "        [-3.9215],\n",
      "        [ 4.7391],\n",
      "        [ 5.8144],\n",
      "        [ 4.6935],\n",
      "        [ 5.5854],\n",
      "        [ 6.1805],\n",
      "        [-1.1847],\n",
      "        [ 2.9480],\n",
      "        [ 8.6727],\n",
      "        [-0.7128],\n",
      "        [ 6.7394],\n",
      "        [10.8994],\n",
      "        [ 0.7015],\n",
      "        [ 0.5530],\n",
      "        [ 0.5239],\n",
      "        [ 0.6209],\n",
      "        [11.4945],\n",
      "        [ 5.6041],\n",
      "        [ 1.5515],\n",
      "        [ 0.9366],\n",
      "        [ 3.3906],\n",
      "        [ 2.1606],\n",
      "        [ 1.3284],\n",
      "        [-0.5069],\n",
      "        [ 7.3654],\n",
      "        [ 7.7831],\n",
      "        [ 8.1037],\n",
      "        [ 0.4792],\n",
      "        [ 3.3315],\n",
      "        [ 5.1938],\n",
      "        [ 0.7311],\n",
      "        [ 7.1533],\n",
      "        [-0.6021],\n",
      "        [-3.8574],\n",
      "        [ 1.8255],\n",
      "        [ 6.9061],\n",
      "        [ 7.5368],\n",
      "        [-0.8621],\n",
      "        [11.2824],\n",
      "        [ 0.1185],\n",
      "        [ 1.1779],\n",
      "        [-1.9446],\n",
      "        [-1.2776],\n",
      "        [ 3.0129],\n",
      "        [ 7.4271],\n",
      "        [-2.6733],\n",
      "        [ 8.7208],\n",
      "        [ 5.5024]])\n"
     ]
    }
   ],
   "source": [
    "print('features', features, \"labels\", labels)\n",
    "# features表示样本元素, labels表示样本元素对应的真是label值.\n",
    "# 这是一个线性回归问题, 因此值是不连续的, 并且是无线的.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0615,  0.0359]) tensor([-0.0480])\n"
     ]
    }
   ],
   "source": [
    "print(features[0], labels[0]) # 第一个数据对应其真实的label值."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5003a15a50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"229.425pt\" height=\"169.678125pt\" viewBox=\"0 0 229.425 169.678125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-10-23T10:48:24.456030</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 169.678125 \nL 229.425 169.678125 \nL 229.425 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 145.8 \nL 222.225 145.8 \nL 222.225 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path id=\"mf3367ee472\" d=\"M 0 0.5 \nC 0.132602 0.5 0.25979 0.447317 0.353553 0.353553 \nC 0.447317 0.25979 0.5 0.132602 0.5 0 \nC 0.5 -0.132602 0.447317 -0.25979 0.353553 -0.353553 \nC 0.25979 -0.447317 0.132602 -0.5 0 -0.5 \nC -0.132602 -0.5 -0.25979 -0.447317 -0.353553 -0.353553 \nC -0.447317 -0.25979 -0.5 -0.132602 -0.5 0 \nC -0.5 0.132602 -0.447317 0.25979 -0.353553 0.353553 \nC -0.25979 0.447317 -0.132602 0.5 0 0.5 \nz\n\" style=\"stroke: #1f77b4\"/>\n    </defs>\n    <g clip-path=\"url(#pdf363ff3a2)\">\n     <use xlink:href=\"#mf3367ee472\" x=\"119.776294\" y=\"108.587383\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"69.748495\" y=\"22.415547\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"158.386529\" y=\"126.912785\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"149.535246\" y=\"139.266323\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"127.548399\" y=\"86.304098\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"117.153738\" y=\"70.147986\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"102.239393\" y=\"72.979972\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"148.647286\" y=\"79.070867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"107.656764\" y=\"55.557406\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"101.867993\" y=\"68.841398\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"169.056053\" y=\"119.275245\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"88.387707\" y=\"15.360561\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"161.589041\" y=\"87.933137\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"35.802273\" y=\"13.589725\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"128.156089\" y=\"56.565975\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"213.347727\" y=\"101.57911\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"86.274555\" y=\"41.426259\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"115.561207\" y=\"81.284766\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"85.585236\" y=\"69.787433\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"147.456897\" y=\"125.824702\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"159.070623\" y=\"97.455651\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"122.7572\" y=\"48.66891\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"119.624759\" y=\"71.996735\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"101.817637\" y=\"83.179089\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"116.870607\" y=\"83.227745\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"68.605115\" y=\"22.847274\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"173.668449\" y=\"110.564517\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"104.144749\" y=\"75.172108\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"188.744842\" y=\"97.523478\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"105.655708\" y=\"51.899903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"112.503016\" y=\"71.759124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"142.414506\" y=\"110.420743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"111.273586\" y=\"52.624412\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"94.6667\" y=\"74.977319\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"91.227896\" y=\"82.609253\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"155.380065\" y=\"88.951503\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"140.526241\" y=\"96.704031\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"68.241521\" y=\"43.519042\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"66.612061\" y=\"48.994256\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"171.16973\" y=\"106.857289\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"150.680922\" y=\"95.261214\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"170.248863\" y=\"108.876494\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"140.288193\" y=\"79.758526\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"107.790267\" y=\"77.650323\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"91.720988\" y=\"70.276382\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"112.947384\" y=\"48.820515\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"87.825836\" y=\"68.403628\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"153.177271\" y=\"115.03599\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"144.454411\" y=\"96.68493\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"132.351586\" y=\"109.971165\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"96.43867\" y=\"13.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"157.819321\" y=\"98.785994\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"204.692892\" y=\"139.5\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"139.490744\" y=\"70.383159\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"115.134438\" y=\"61.802059\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"97.648971\" y=\"70.74743\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"81.104863\" y=\"63.629246\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"89.790801\" y=\"58.879896\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"154.498043\" y=\"117.658439\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"107.13891\" y=\"84.677117\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"85.488718\" y=\"38.990811\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"160.19624\" y=\"113.892765\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"106.653051\" y=\"54.419881\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"71.568278\" y=\"21.220238\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"122.056855\" y=\"102.605173\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"190.620351\" y=\"103.790705\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"161.521224\" y=\"104.022728\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"153.431039\" y=\"103.249035\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"96.340402\" y=\"16.471428\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"114.441495\" y=\"63.480062\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"154.538829\" y=\"95.821867\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"134.40392\" y=\"100.729109\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"132.726399\" y=\"81.145133\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"173.593555\" y=\"90.960769\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"139.096837\" y=\"97.602621\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"187.049331\" y=\"112.24924\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"93.730398\" y=\"49.423734\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"100.494762\" y=\"46.090291\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"99.608891\" y=\"43.531395\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"144.100525\" y=\"104.379247\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"111.195942\" y=\"81.616366\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"139.215783\" y=\"66.754045\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"154.486464\" y=\"102.369349\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"81.961166\" y=\"51.116147\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"192.045886\" y=\"113.009342\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"192.240099\" y=\"138.987903\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"159.92366\" y=\"93.635569\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"111.219509\" y=\"53.089364\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"92.068014\" y=\"48.055916\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"163.1084\" y=\"115.084223\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"82.284041\" y=\"18.163865\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"145.474766\" y=\"107.258502\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"131.190701\" y=\"98.804\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"189.773961\" y=\"123.722826\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"178.149\" y=\"118.399726\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"139.34098\" y=\"84.159323\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"91.963435\" y=\"48.931478\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"183.102876\" y=\"129.538784\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"99.94288\" y=\"38.607124\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n     <use xlink:href=\"#mf3367ee472\" x=\"107.499881\" y=\"64.29183\" style=\"fill: #1f77b4; stroke: #1f77b4\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mb01eacd90c\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mb01eacd90c\" x=\"44.797812\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −2 -->\n      <g transform=\"translate(37.426718 160.398438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mb01eacd90c\" x=\"81.626205\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −1 -->\n      <g transform=\"translate(74.255111 160.398438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mb01eacd90c\" x=\"118.454598\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0 -->\n      <g transform=\"translate(115.273348 160.398438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mb01eacd90c\" x=\"155.282991\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1 -->\n      <g transform=\"translate(152.101741 160.398438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mb01eacd90c\" x=\"192.111384\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2 -->\n      <g transform=\"translate(188.930134 160.398438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path id=\"m0431eca310\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m0431eca310\" x=\"26.925\" y=\"108.20392\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 112.003139)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m0431eca310\" x=\"26.925\" y=\"68.301045\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 72.100264)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m0431eca310\" x=\"26.925\" y=\"28.39817\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 32.197389)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 145.8 \nL 26.925 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 222.225 145.8 \nL 222.225 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 145.8 \nL 222.225 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 222.225 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pdf363ff3a2\">\n   <rect x=\"26.925\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 此时我们可以调用d2l中的图功能, 以此来查看整体样本关系\n",
    "d2l.set_figsize()\n",
    "d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1)\n",
    "# d2l.plt.imshow()\n",
    "\n",
    "# 使用detach()的目的, 是因为torch老版本中, 需要先将tensor, 从图中抽离出来, 所以就要使用detach()将数据抽离出来."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据集:\n",
    "# 我们回想一下对数据集进行遍历, 并且我们是小批量的样本, 来更新我们的模型\n",
    "# 这是机器学习算法基础, 也就是我们必须要定义一个函数, 该函数能够打乱数据集合中的样本\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_example = len(labels)\n",
    "    indices = list(range(num_example)) # 序列\n",
    "    # 为什么是随机梯度下降: SGD, shuffle\n",
    "    random.shuffle(indices) # 打乱index\n",
    "    for i in range(0, num_example, batch_size): # 0到end, 每batchsize一组, 这样能保证遍历一边数据集\n",
    "        tensor = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_example)]  # 取出feature, min, 是考虑最后一组时, batch_size过大, 导致数组越界.\n",
    "        )\n",
    "        batch_indices = tensor\n",
    "        # 使用生成器.\n",
    "        yield features[batch_indices], labels[batch_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3653,  0.5671],\n",
      "        [ 1.5277,  1.4972],\n",
      "        [-1.5696,  0.3773],\n",
      "        [ 2.6939,  2.5766],\n",
      "        [-1.0283, -1.0142],\n",
      "        [ 0.2224,  0.0318],\n",
      "        [ 0.8109,  1.0026],\n",
      "        [ 0.9436, -1.3536],\n",
      "        [-0.4897,  0.5605],\n",
      "        [ 0.9643, -0.4877]]) tensor([[ 3.0129],\n",
      "        [ 2.1606],\n",
      "        [-0.2214],\n",
      "        [ 0.8301],\n",
      "        [ 5.5854],\n",
      "        [ 4.5369],\n",
      "        [ 2.4124],\n",
      "        [10.6956],\n",
      "        [ 1.3284],\n",
      "        [ 7.7831]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "# 使用迭代器, 取出数据\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, y)\n",
    "    break\n",
    "# 但是这种迭代方式, 逻辑上是很清晰, 但是执行效率会很低. 尽管我们用上了iter. 可能会在实际问题上出现问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0107],\n",
       "         [0.0051]], requires_grad=True),\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 然后定义模型\n",
    "# 初始化参数:\n",
    "w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True) # 并且我们是需要保留梯度的\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "w, b # 随机初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def linear_regression(X, w, b):\n",
    "    \"\"\"线性模型运算, 返回y_hat\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数:\n",
    "def mean_squared_loss(y_hat, y):\n",
    "    \"均方损失\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化算法:\n",
    "def sgd(params, lr, batch_size):\n",
    "    \"\"\"\n",
    "    这里使用的是小批量随机梯度下降,\n",
    "    params is a container, include all parameter \n",
    "    can use a list data-struction, to include params.\n",
    "    \n",
    "    \"\"\"\n",
    "    with torch.no_grad(): # 不保存梯度, 这样能够计算的速度快一些. \n",
    "        for param in params: # 遍历每个参数, 都向－梯度更新. \n",
    "            param -= lr * param.grad / batch_size # 这里的batch_size是为了让模型更加平均的更新\n",
    "            param.grad.zero_() # empty gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练: \n",
    "# 设定超参数:\n",
    "lr = 0.03\n",
    "num_epoch = 10 # epoch 轮数\n",
    "net = linear_regression # 网络\n",
    "loss = mean_squared_loss # 损失函数\n",
    "optimize = sgd # 优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练：\n",
    "for epoch in range(num_epoch): # 每一轮\n",
    "    # 扫一遍batch:\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        # 计算y_hat\n",
    "        y_hat = net(X, w, b)\n",
    "        # 计算loss:\n",
    "        loss_scalar = loss(y_hat, y)\n",
    "        # 计算params梯度, 准备更新\n",
    "        loss_scalar.sum().backward() # 我们通常是对一个标量进行求梯度的操作. 这样我们在反向传播\n",
    "        # 有了grad随后进行更新:\n",
    "        optimize([w, b], lr, batch_size)\n",
    "    # 扫完所有的batch, 进行评估\n",
    "    with torch.no_grad(): # 评估时, 不需要计算梯度, 节省资源\n",
    "        train_loss_scalar = loss(net(features, w, b),  labels) # 计算一下每轮的损失\n",
    "        print(f'epoch: {epoch+1}, loss: {float(train_loss_scalar.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference of 'w': tensor([-0.0090, -0.0321], grad_fn=<SubBackward0>)\n",
      "difference of 'b': tensor([0.0274], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 看一下训练完后的真实值与估计值的差距:\n",
    "print(f\"difference of 'w': {true_w - w.reshape(true_w.shape)}\")\n",
    "print(f\"difference of 'b': {true_b - b}\")\n",
    "# 可见, 经过训练差距还是非常小的. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
